# -*- coding: utf-8 -*-
"""CHDModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wIr2wedLXVH3iGA66YDn6VYAdiWXNASX
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import pandas as pd
import tensorflow as tf
import numpy as np
from tensorflow import feature_column

# Reference: https://www.tensorflow.org/tutorials/structured_data/feature_columns
# Used to parse csv data and convert to data sets 

# upload the heart_train.csv and heart_test.csv
from google.colab import files
uploaded = files.upload()

train_df = pd.read_csv('heart_train.csv')

cols = []

for header in ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']:
  cols.append(tf.feature_column.numeric_column(header))

train_df['famhist'] = train_df['famhist'].apply(str)
famhist_train = tf.feature_column.categorical_column_with_vocabulary_list('famhist', ['Present', 'Absent'])
famhist_trainH = tf.feature_column.indicator_column(famhist_train)
cols.append(famhist_trainH)

# taken directly from: https://www.tensorflow.org/tutorials/structured_data/feature_columns
def df_to_dataset(df, batch_size=32):
  df = df.copy()
  labels = df.pop('chd')
  return tf.data.Dataset.from_tensor_slices((dict(df), labels)) \
          .shuffle(buffer_size=len(df)) \
          .batch(batch_size)


test_df = pd.read_csv('heart_test.csv')
test_df['famhist'] = test_df['famhist'].apply(str)
famhist_test = tf.feature_column.categorical_column_with_vocabulary_list('famhist', ['Present', 'Absent'])
famhist_testH = tf.feature_column.indicator_column(famhist_test)

train_dataset = df_to_dataset(train_df)
test_dataset = df_to_dataset(test_df)

#df.head()
# df2.head()
# for i in cols:
#   print(i)

#df2.head()

print("--Make model--")
model = tf.keras.models.Sequential([
  tf.keras.layers.DenseFeatures(cols),
  tf.keras.layers.Dense(256, 'relu'),
  tf.keras.layers.Dropout(0.50),
  tf.keras.layers.Dense(256, 'relu'),
  tf.keras.layers.Dropout(0.50),
  tf.keras.layers.Dense(256, 'relu'),
  tf.keras.layers.Dropout(0.50),
  tf.keras.layers.Dense(256, 'relu'),
  tf.keras.layers.Dropout(0.50),
  tf.keras.layers.Dense(units = 1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("--Fit model--")
model.fit(train_dataset, epochs= 300 , verbose=2)

print("--Evaluate model--")
model_loss, model_acc = model.evaluate(test_dataset, verbose=2)
print(f"Model Loss:    {model_loss:.2f}")
print(f"Model Accuracy: {model_acc*100:.1f}%")